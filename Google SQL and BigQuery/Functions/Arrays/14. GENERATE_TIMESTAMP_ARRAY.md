‚è±Ô∏è **BigQuery Real-World Trick: Generate Time Series Data in Seconds with `GENERATE_TIMESTAMP_ARRAY()`**

A few weeks ago, I was building a **real-time event monitoring dashboard** ‚Äî and I ran into a classic data engineering problem üëá

Our dataset had **irregular event timestamps** (e.g., logs coming in every few minutes), but the dashboard needed to display **data for every minute**, even if **no event occurred** during that minute.

Instead of creating a separate time dimension table or using complex joins‚Ä¶
I solved it with a single BigQuery function: **`GENERATE_TIMESTAMP_ARRAY()`** ‚ö°

---

‚è±Ô∏è **BigQuery Real-World Trick: Generate Time Series Data in Seconds with `GENERATE_TIMESTAMP_ARRAY()`**

üîß **What it does:**
`GENERATE_TIMESTAMP_ARRAY(start_timestamp, end_timestamp, INTERVAL n unit)`
It creates an array of timestamps between two points ‚Äî with any interval you want (`SECOND`, `MINUTE`, `HOUR`, `DAY`, etc.).

```sql
GENERATE_TIMESTAMP_ARRAY(start_timestamp, end_timestamp,
                         INTERVAL step_expression date_part)
```

### **Description**

Returns an ARRAY of TIMESTAMPS separated by a given interval. The start_timestamp and end_timestamp parameters determine the inclusive lower and upper bounds of the ARRAY.

The GENERATE_TIMESTAMP_ARRAY function accepts the following data types as inputs:

start_timestamp: TIMESTAMP
end_timestamp: TIMESTAMP
step_expression: INT64
Allowed date_part values are: MICROSECOND, MILLISECOND, SECOND, MINUTE, HOUR, or DAY.
The step_expression parameter determines the increment used to generate timestamps.

Return Data Type

An ARRAY containing 0 or more TIMESTAMP values.

---

‚úÖ **Example 1: Generate timestamps every 1 hour**

```sql
SELECT GENERATE_TIMESTAMP_ARRAY(
  '2025-10-01 00:00:00',
  '2025-10-01 05:00:00',
  INTERVAL 1 HOUR
) AS timestamps;
```

üìä Output:

```
[2025-10-01 00:00:00+00, 2025-10-01 01:00:00+00, ..., 2025-10-01 05:00:00+00]
```

---

‚úÖ **Real-world use case: Fill missing time intervals for log data**

```sql
WITH timeline AS (
  SELECT ts
  FROM UNNEST(GENERATE_TIMESTAMP_ARRAY(
    '2025-10-01 00:00:00',
    '2025-10-01 23:59:00',
    INTERVAL 1 MINUTE
  )) AS ts
)
SELECT 
  t.ts,
  COALESCE(SUM(e.event_count), 0) AS events
FROM timeline t
LEFT JOIN `project.dataset.events` e
ON TIMESTAMP_TRUNC(e.event_time, MINUTE) = t.ts
GROUP BY t.ts
ORDER BY t.ts;
```

üìà **Result:**

* Every minute of the day appears in your result.
* Even when no events occurred, you get `0`.
* Your charts and anomaly detection pipelines become much more accurate ‚úÖ

üí° **Other awesome use cases:**

* Building time series for IoT or sensor data
* Monitoring gaps in streaming pipelines
* Creating hourly or minute-based KPIs for dashboards
* Simulating event data for testing


üî• **Pro Tip:** Combine `GENERATE_TIMESTAMP_ARRAY()` with `TIMESTAMP_TRUNC()` for powerful time bucketing and aggregation patterns.


## ‚è±Ô∏è **Real-World BigQuery Trick: Generate Time-Series Data for Dashboards with `GENERATE_TIMESTAMP_ARRAY()`**

Last week, I needed to test a streaming dashboard, but there was one problem‚Ä¶
üëâ Our events table was empty in the dev environment.

Instead of waiting for real data, I quickly **generated a realistic timestamp series** directly inside BigQuery using `GENERATE_TIMESTAMP_ARRAY()` ‚Äî and even inserted it into a table. üí°

Here‚Äôs how I did it üëá

---

‚úÖ **Step 1: Create a demo table**

```sql
CREATE OR REPLACE TABLE `my_project.my_dataset.sensor_events` (
  event_time TIMESTAMP,
  temperature FLOAT64
);
```

---

‚úÖ **Step 2: Generate hourly timestamps and insert data**

```sql
INSERT INTO `my_project.my_dataset.sensor_events` (event_time, temperature)
SELECT
  ts,
  20 + RAND() * 5  -- Random temperature between 20 and 25
FROM UNNEST(
  GENERATE_TIMESTAMP_ARRAY(
    '2025-10-01 00:00:00',
    '2025-10-02 00:00:00',
    INTERVAL 1 HOUR
  )
) AS ts;
```

üìä **What this does:**

* Generates hourly timestamps for 24 hours.
* Assigns a random temperature value for each timestamp.
* Inserts 24 rows of realistic IoT-like data into the table.

---

‚úÖ **Step 3: Query the time-series data**

```sql
SELECT 
  event_time,
  temperature
FROM `my_project.my_dataset.sensor_events`
ORDER BY event_time;
```

üìà **Result:**

| event_time             | temperature |
| ---------------------- | ----------- |
| 2025-10-01 00:00:00+00 | 22.4        |
| 2025-10-01 01:00:00+00 | 21.8        |
| 2025-10-01 02:00:00+00 | 24.1        |
| ...                    | ...         |

‚úÖ Now I had a fully working **time-series dataset** to test dashboards, build queries, and experiment with analytics ‚Äî all without needing any real data.

---

üí° **Pro Tip:**
You can change the interval to `1 MINUTE` or `1 SECOND` for finer-grained event data, or extend the end time to generate weeks of data for forecasting and trend analysis.

---

This approach is a **lifesaver** for:

* Testing dashboards before real data arrives
* Creating synthetic IoT or sensor event streams
* Backfilling missing data in time series
* Building anomaly detection POCs

---

Would you try this trick in your next project? üëá
It‚Äôs one of those ‚Äúsmall but powerful‚Äù SQL techniques that can save hours of engineering time. ‚è±Ô∏è

